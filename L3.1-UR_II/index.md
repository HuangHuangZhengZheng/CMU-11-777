# Lecture 3.1: Unimodal Representation II


## Word Representation

- Distribution hypothesis: using the context
- words in similar contexts are similar in meaning :thinking:

- word counting

- actually, building a subspace of word vectors is those vector space models of words do

> Word2Vec, ELMO, BERT


### language modeling

RNN-based language models

pretraining and masking




